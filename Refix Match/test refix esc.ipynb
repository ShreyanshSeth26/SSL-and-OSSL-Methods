{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8053004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: car_horn\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as Models\n",
    "\n",
    "class AudioDenseNet(nn.Module):\n",
    "    def __init__(self, NumClasses=50):\n",
    "        super().__init__()\n",
    "        self.Backbone = Models.densenet121(weights=Models.DenseNet121_Weights.DEFAULT)\n",
    "        self.Backbone.features.conv0 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=64,\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            padding=3,\n",
    "            bias=False\n",
    "        )\n",
    "        nn.init.kaiming_normal_(self.Backbone.features.conv0.weight, mode='fan_out', nonlinearity='relu')\n",
    "        NumFeats = self.Backbone.classifier.in_features\n",
    "        self.Backbone.classifier = nn.Linear(NumFeats, NumClasses)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.Backbone(X)\n",
    "\n",
    "def classify_audio(audio_path, model, classNames, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), target_sr=None):\n",
    "    signal, sr = librosa.load(audio_path, sr=target_sr)\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=signal,\n",
    "        sr=sr,\n",
    "        n_fft=2048,\n",
    "        hop_length=512,\n",
    "        n_mels=128\n",
    "    )\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "    mel_tensor = torch.tensor(mel_db, dtype=torch.float).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(mel_tensor)\n",
    "        probs = F.softmax(logits, dim=1).cpu().numpy().squeeze()\n",
    "        pred_idx = np.argmax(probs)\n",
    "    \n",
    "    pred_class = classNames[pred_idx]\n",
    "    return pred_class, probs[pred_idx], probs\n",
    "\n",
    "classNames = [\n",
    "    \"airplane\", \"breathing\", \"brushing_teeth\", \"can_opening\", \"car_horn\", \n",
    "    \"cat\", \"chainsaw\", \"chirping_birds\", \"church_bells\", \"clapping\", \n",
    "    \"clock_alarm\", \"clock_tick\", \"coughing\", \"cow\", \"crackling_fire\", \n",
    "    \"crickets\", \"crow\", \"crying_baby\", \"dog\", \"door_wood_creaks\", \n",
    "    \"door_wood_knock\", \"drinking_sipping\", \"engine\", \"fireworks\", \n",
    "    \"footsteps\", \"frog\", \"glass_breaking\", \"hand_saw\", \"helicopter\", \n",
    "    \"hen\", \"insects\", \"keyboard_typing\", \"laughing\", \"mouse_click\", \n",
    "    \"pig\", \"pouring_water\", \"rain\", \"rooster\", \"sea_waves\", \"sheep\", \n",
    "    \"siren\", \"sneezing\", \"snoring\", \"thunderstorm\", \"toilet_flush\", \n",
    "    \"train\", \"vacuum_cleaner\", \"washing_machine\", \"water_drops\", \"wind\"\n",
    "]\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = AudioDenseNet(NumClasses=len(classNames)).to(device)\n",
    "weights_path = r\"C:\\Users\\clash\\Downloads\\mkc\\Refix Match\\ReFixMatch_ESC50_17_PerClass.pth\"\n",
    "model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "audio_path = r\"C:\\Users\\clash\\Downloads\\mkc\\4.wav\"\n",
    "pred_class, confidence, prob_vector = classify_audio(audio_path, model, classNames, device)\n",
    "print(\"Predicted Class:\", pred_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
